error 1

AttributeError: 'Series' object has no attribute 'ast'
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
File <command-4610719396430380>, line 17
      4 all_loss_codes_df = get_loss_df_for_embeddings(scs_loss_codes, scs_components)
      6 parts_only_his_fin_df = (no_rank_df
      7                          .select('spart_no', F.col('initial_part_desc').alias('spart_desc'), F.trim(F.col("CORRECTION")).alias("corrective_action"))
      8                          .withColumn("spart_desc", F.lower(F.trim(F.col('spart_desc'))))
   (...)
     14                          
     15 )
---> 17 similarity_matrix, top_matches, flat_matrix =  main_embedding_ranking(
     18                                                                         loss_codes_df = all_loss_codes_df, 
     19                                                                         parts_only_his_fin_df=parts_only_his_fin_df,
     20                                                                         top_n=10,
     21                                                                         use_both_sources=True 
     22                                                                         )
     24 updated_rank_df = get_updated_rank_df_with_missing(rank_df, top_matches)

File <command-4610719396430811>, line 25, in main_embedding_ranking(loss_codes_df, parts_only_his_fin_df, api_key, top_n, efficient, use_both_sources, save_loss_embedding, upsert_part_save, upsert_corrective_save, OUTPUT_DIR, BASE_DIR, embedding_path)
     22     print("Warning: corrective_action column not found in parts dataframe. Using part descriptions only.")
     23     use_both_sources = False
---> 25 similarity_matrix, top_matches_part, top_matches_corrective, flat_matrix = calculate_similarity_for_databricks(
     26     loss_df=loss_code_df_pd,
     27     parts_df=part_only_his_fin_df_pd,
     28     openai_api_key=api_key,
     29     top_n=top_n,
     30     efficient=efficient,
     31     use_both_sources=use_both_sources,
     32     OUTPUT_DIR=OUTPUT_DIR,
     33     BASE_DIR=BASE_DIR,
     34     embedding_path=embedding_path,
     35     save_loss_embedding=save_loss_embedding,
     36     upsert_part_save=upsert_part_save,
     37     upsert_corrective_save=upsert_corrective_save
     38 )
     40 print("\n=== Job Completed ===")
     41 if similarity_matrix is not None:

File <command-4610719396430810>, line 24, in calculate_similarity_for_databricks(loss_df, parts_df, openai_api_key, top_n, efficient, use_both_sources, OUTPUT_DIR, BASE_DIR, embedding_path, save_loss_embedding, upsert_part_save, upsert_corrective_save)
     15 """Main callable for Databricks notebooks."""
     17 calculator = SimilarityCalculator(
     18     openai_api_key=openai_api_key,
     19     model="text-embedding-3-small",
     20     cache_path=f"{BASE_DIR}/similarity_cache",
     21     embedding_store_path=embedding_path
     22 )
---> 24 save_created_embeddings(
     25     loss_code_df=loss_df,
     26     part_only_his_fin_df=parts_df,
     27     calculator=calculator,
     28     loss=save_loss_embedding,
     29     upsert_part=upsert_part_save,
     30     upsert_corrective=upsert_corrective_save,
     31     embedding_path=embedding_path
     32 )
     34 if efficient:
     35     print("Using efficient top-N...")

File <command-4610719396430809>, line 210, in save_created_embeddings(loss_code_df, part_only_his_fin_df, calculator, loss, upsert_part, upsert_corrective, embedding_path)
    207 else:
    208     existing_parts_emb_df = None
--> 210 updated_parts_emb_df = upsert_part_embeddings(
    211     parts_df=part_only_his_fin_df,
    212     calculator=calculator,
    213     existing_parts_emb_df=existing_parts_emb_df,
    214     id_col="spart_no",
    215     text_col="spart_desc",
    216     batch_size=512
    217 )
    218 print(f"Saving part embeddings to {part_emb_store}")
    219 updated_parts_emb_df.to_parquet(part_emb_store, index=False)

File <command-4610719396430809>, line 60, in upsert_part_embeddings(parts_df, calculator, existing_parts_emb_df, id_col, text_col, batch_size)
     57 if new_rows.empty:
     58     return existing.reset_index(drop=True)
---> 60 texts = new_rows[text_col].fillna("").ast(str).tolist()
     61 embs = calculator.get_embeddings_batch(texts, batch_size=batch_size)
     63 ts = datetime.utcnow().isoformat()

File /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/pandas/core/generic.py:6204, in NDFrame.__getattr__(self, name)
   6197 if (
   6198     name not in self._internal_names_set
   6199     and name not in self._metadata
   6200     and name not in self._accessors
   6201     and self._info_axis._can_hold_identifiers_and_holds_name(name)
   6202 ):
   6203     return self[name]
-> 6204 return object.__getattribute__(self, name)

AttributeError: 'Series' object has no attribute 'ast'
